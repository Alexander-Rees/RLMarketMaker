# Real AAPL data configuration for RL training

# Data source
data_path: "data/polygon/aapl_ticks.parquet"
symbol: "AAPL"
timeframe: "1min"

# Episode parameters
episode_length: 1000
warmup_steps: 100

# Domain randomization (applied to real data)
volatility_multiplier: [0.8, 1.2]
spread_multiplier: [0.5, 1.5]
latency_range: [1, 5]
fee_range: [0.0001, 0.0005]

# Risk controls
max_inventory: 100.0
max_loss_per_episode: 100.0
kill_switch_threshold: -200.0

# Reward parameters
lambda_inventory: 0.001
transaction_fee: 0.00005

# Training parameters
total_timesteps: 100000
eval_freq: 10000
save_freq: 20000
log_interval: 10

# Logging
log_dir: "logs"
tensorboard_log: "logs/tensorboard"
verbose: 1
